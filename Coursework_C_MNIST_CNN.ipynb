{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2B4x1lj_8rhI"
      },
      "source": [
        "# Practical Machine Learning for Physicists\n",
        "## Coursework C -- Part 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqH_R6yA8rhK"
      },
      "source": [
        "### Task 1:\n",
        "Design, implement and test a neural network utilising a single convolutional layer (use as many other non convolutional layers as you need) to classify the MNIST handwritten digits. What is the maximum test accuracry you can achieve using a single convolutional layer?\n",
        "\n",
        "### Task 2:\n",
        "Design, implement and test a neural network utitlising multiple convolutional layers (again use as many other non convolutinal laters as you need) to classify the MNIST handwritten digits. What is the maximum test accuracry you can achieve using as many convolutional layers as you like?\n",
        "\n",
        "#### Practicalities\n",
        "You should use this notebook for your work and upload it to Moodle. You are expected to use TensorFlow and Keras to complete these takss. The notebook should be self-contained and able to be executed if necessary. Marks will be awarded for (roughly equally weighted):\n",
        "- Overall notebook clarity (both in terms of good coding practice and coherent discussion)\n",
        "- Network performance (how well does your classifier do?)\n",
        "- Network efficiency (how does your network compare to the optimum networks for this task?)\n",
        "- Network training (do you do a good job of traning your network?)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "\n",
        "Train a model with Conventional layer to classify the MNIST handwritten digits. The aim is to achieve the maximum test accuracy using both single convolutional layer and multiple convolutional layers"
      ],
      "metadata": {
        "id": "ECKwMslR85XM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import necessary library"
      ],
      "metadata": {
        "id": "xwuT51u_FMlT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3qZ_U2Y8rhL",
        "outputId": "c615d158-301c-4c29-9c46-b23811b447f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "## importing the necessary library\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.style #Some style nonsense\n",
        "import matplotlib as mpl #Some more style nonsense\n",
        "\n",
        "\n",
        "#Set default figure size\n",
        "#mpl.rcParams['figure.figsize'] = [12.0, 8.0] #Inches... of course it is inches\n",
        "mpl.rcParams[\"legend.frameon\"] = False\n",
        "mpl.rcParams['figure.dpi']=200 # dots per inch\n",
        "\n",
        "#Useful for debugging problems\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Load the MNIST dataset\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print(train_images.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_images.shape)\n",
        "print(test_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFdtEGS99Xyn",
        "outputId": "da46cc48-09e0-4106-c239-9eae1bf83991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalise the image's pixel\n",
        "\n",
        "train_images=train_images/255.0\n",
        "test_images=test_images/255.0"
      ],
      "metadata": {
        "id": "IUsQogZn9pD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neutral Network Containing a single Convolutional neutral layer\n",
        "\n",
        "In this section of the notebook, we design a model with a single convolutional neutral layer which is then followed by a down pooling and then flatten to go through the dense hidden dense layer with 40 neurons. Finally, the model return 10 outputs (with probably for each of them) which corresponds to possible digits in the MNIST data."
      ],
      "metadata": {
        "id": "jMnk5L2LDZ4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Design the neutral network layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32,kernel_size=(3,3),activation='relu', input_shape=(28,28,1)),\n",
        "    keras.layers.AveragePooling2D(pool_size=(3,3),padding='same'),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(30,activation='relu'),\n",
        "    keras.layers.Dense(10,activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=tf.keras.optimizers.SGD(lr=1.0),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ymn_BX1K9qt9",
        "outputId": "89c49d02-65f6-48d8-a9e7-73e8591946bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " average_pooling2d (Average  (None, 9, 9, 32)          0         \n",
            " Pooling2D)                                                      \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2592)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 30)                77790     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                310       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 78420 (306.33 KB)\n",
            "Trainable params: 78420 (306.33 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "ud0VFh9wFUC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(train_images, train_labels,batch_size=128, epochs=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAkjjVB9B40y",
        "outputId": "3f2c8584-7dd9-4702-a586-788eb852762b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "469/469 [==============================] - 19s 39ms/step - loss: 1.5035 - accuracy: 0.6035\n",
            "Epoch 2/30\n",
            "469/469 [==============================] - 16s 35ms/step - loss: 0.4949 - accuracy: 0.8690\n",
            "Epoch 3/30\n",
            "469/469 [==============================] - 16s 35ms/step - loss: 0.3751 - accuracy: 0.8947\n",
            "Epoch 4/30\n",
            "469/469 [==============================] - 17s 35ms/step - loss: 0.3356 - accuracy: 0.9039\n",
            "Epoch 5/30\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.3129 - accuracy: 0.9092\n",
            "Epoch 6/30\n",
            "469/469 [==============================] - 17s 35ms/step - loss: 0.2968 - accuracy: 0.9139\n",
            "Epoch 7/30\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.2843 - accuracy: 0.9171\n",
            "Epoch 8/30\n",
            "469/469 [==============================] - 16s 35ms/step - loss: 0.2729 - accuracy: 0.9198\n",
            "Epoch 9/30\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.2638 - accuracy: 0.9231\n",
            "Epoch 10/30\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.2547 - accuracy: 0.9256\n",
            "Epoch 11/30\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.2477 - accuracy: 0.9272\n",
            "Epoch 12/30\n",
            "469/469 [==============================] - 17s 36ms/step - loss: 0.2410 - accuracy: 0.9298\n",
            "Epoch 13/30\n",
            "469/469 [==============================] - 15s 32ms/step - loss: 0.2345 - accuracy: 0.9314\n",
            "Epoch 14/30\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.2287 - accuracy: 0.9335\n",
            "Epoch 15/30\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.2227 - accuracy: 0.9342\n",
            "Epoch 16/30\n",
            "469/469 [==============================] - 16s 35ms/step - loss: 0.2172 - accuracy: 0.9363\n",
            "Epoch 17/30\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.2120 - accuracy: 0.9373\n",
            "Epoch 18/30\n",
            "469/469 [==============================] - 15s 32ms/step - loss: 0.2066 - accuracy: 0.9403\n",
            "Epoch 19/30\n",
            "469/469 [==============================] - 15s 32ms/step - loss: 0.2026 - accuracy: 0.9405\n",
            "Epoch 20/30\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.1980 - accuracy: 0.9419\n",
            "Epoch 21/30\n",
            "469/469 [==============================] - 16s 35ms/step - loss: 0.1936 - accuracy: 0.9435\n",
            "Epoch 22/30\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.1891 - accuracy: 0.9445\n",
            "Epoch 23/30\n",
            "469/469 [==============================] - 15s 32ms/step - loss: 0.1860 - accuracy: 0.9458\n",
            "Epoch 24/30\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.1818 - accuracy: 0.9463\n",
            "Epoch 25/30\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.1779 - accuracy: 0.9480\n",
            "Epoch 26/30\n",
            "469/469 [==============================] - 17s 36ms/step - loss: 0.1750 - accuracy: 0.9485\n",
            "Epoch 27/30\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.1717 - accuracy: 0.9493\n",
            "Epoch 28/30\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.1689 - accuracy: 0.9503\n",
            "Epoch 29/30\n",
            "469/469 [==============================] - 14s 31ms/step - loss: 0.1658 - accuracy: 0.9508\n",
            "Epoch 30/30\n",
            "469/469 [==============================] - 15s 31ms/step - loss: 0.1637 - accuracy: 0.9512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the model using the MNIST test sample\n"
      ],
      "metadata": {
        "id": "oVlfQO-MFWtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss,test_acc=model.evaluate(test_images,test_labels,verbose=2)\n",
        "print(\"The accuracy of the trained model is \", test_acc *100, \"%\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cH5SgY58_Fak",
        "outputId": "7b86e9c7-dba6-4a19-dcd2-e34c1ba6029b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 2s - loss: 0.1662 - accuracy: 0.9510 - 2s/epoch - 6ms/step\n",
            "The accuracy of the trained model is  95.09999752044678 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "honm5ULgDYS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neutral Network Containing Multiple Convolution Neutral layers\n",
        "\n",
        "similar idea to the previous single convolution neutral network but with additional convolutional neutral layer being added."
      ],
      "metadata": {
        "id": "PSH7USh2WD2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Design a new multi-convolution neutral network\n",
        "\n",
        "model2 = keras.Sequential([\n",
        "    keras.layers.Conv2D(32,kernel_size=(3,3),activation='relu', input_shape=(28,28,1),padding='same'),\n",
        "    keras.layers.AveragePooling2D(pool_size=(3,3),padding='same'),\n",
        "    keras.layers.Conv2D(64,kernel_size=(3,3),activation='relu',padding='same'),\n",
        "    keras.layers.AveragePooling2D(pool_size=(3,3),padding='same'),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(30,activation='relu'),\n",
        "    keras.layers.Dense(10,activation='softmax')\n",
        "])\n",
        "\n",
        "model2.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=tf.keras.optimizers.SGD(lr=1.0),\n",
        "              metrics=['accuracy'])\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hWx8GndWWFN",
        "outputId": "b640c785-9f69-4868-e889-ebd3c0411ba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " average_pooling2d_1 (Avera  (None, 10, 10, 32)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 10, 10, 64)        18496     \n",
            "                                                                 \n",
            " average_pooling2d_2 (Avera  (None, 4, 4, 64)          0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 30)                30750     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                310       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 49876 (194.83 KB)\n",
            "Trainable params: 49876 (194.83 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "S8Sms5-JFed2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history2=model2.fit(train_images, train_labels,batch_size=128, epochs=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Chii24uLWs94",
        "outputId": "204af28b-34f0-4194-9e2a-2a4698230853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "469/469 [==============================] - 37s 78ms/step - loss: 2.2862 - accuracy: 0.2414\n",
            "Epoch 2/30\n",
            "469/469 [==============================] - 37s 79ms/step - loss: 2.1704 - accuracy: 0.4527\n",
            "Epoch 3/30\n",
            "469/469 [==============================] - 36s 77ms/step - loss: 1.3713 - accuracy: 0.6640\n",
            "Epoch 4/30\n",
            "469/469 [==============================] - 37s 79ms/step - loss: 0.7218 - accuracy: 0.7872\n",
            "Epoch 5/30\n",
            "469/469 [==============================] - 37s 78ms/step - loss: 0.5784 - accuracy: 0.8250\n",
            "Epoch 6/30\n",
            "469/469 [==============================] - 36s 77ms/step - loss: 0.5003 - accuracy: 0.8487\n",
            "Epoch 7/30\n",
            "469/469 [==============================] - 36s 78ms/step - loss: 0.4425 - accuracy: 0.8659\n",
            "Epoch 8/30\n",
            "469/469 [==============================] - 36s 78ms/step - loss: 0.3969 - accuracy: 0.8806\n",
            "Epoch 9/30\n",
            "469/469 [==============================] - 36s 76ms/step - loss: 0.3609 - accuracy: 0.8926\n",
            "Epoch 10/30\n",
            "469/469 [==============================] - 37s 78ms/step - loss: 0.3311 - accuracy: 0.9002\n",
            "Epoch 11/30\n",
            "469/469 [==============================] - 37s 78ms/step - loss: 0.3064 - accuracy: 0.9085\n",
            "Epoch 12/30\n",
            "469/469 [==============================] - 36s 77ms/step - loss: 0.2834 - accuracy: 0.9148\n",
            "Epoch 13/30\n",
            "469/469 [==============================] - 37s 79ms/step - loss: 0.2665 - accuracy: 0.9201\n",
            "Epoch 14/30\n",
            "469/469 [==============================] - 36s 77ms/step - loss: 0.2503 - accuracy: 0.9251\n",
            "Epoch 15/30\n",
            "469/469 [==============================] - 37s 78ms/step - loss: 0.2364 - accuracy: 0.9306\n",
            "Epoch 16/30\n",
            "469/469 [==============================] - 37s 78ms/step - loss: 0.2247 - accuracy: 0.9331\n",
            "Epoch 17/30\n",
            "469/469 [==============================] - 37s 78ms/step - loss: 0.2136 - accuracy: 0.9370\n",
            "Epoch 18/30\n",
            "469/469 [==============================] - 37s 79ms/step - loss: 0.2033 - accuracy: 0.9393\n",
            "Epoch 19/30\n",
            "469/469 [==============================] - 36s 78ms/step - loss: 0.1951 - accuracy: 0.9424\n",
            "Epoch 20/30\n",
            "469/469 [==============================] - 35s 74ms/step - loss: 0.1866 - accuracy: 0.9447\n",
            "Epoch 21/30\n",
            "469/469 [==============================] - 37s 78ms/step - loss: 0.1802 - accuracy: 0.9466\n",
            "Epoch 22/30\n",
            "469/469 [==============================] - 37s 79ms/step - loss: 0.1746 - accuracy: 0.9481\n",
            "Epoch 23/30\n",
            "469/469 [==============================] - 37s 78ms/step - loss: 0.1688 - accuracy: 0.9499\n",
            "Epoch 24/30\n",
            "469/469 [==============================] - 36s 78ms/step - loss: 0.1635 - accuracy: 0.9517\n",
            "Epoch 25/30\n",
            "469/469 [==============================] - 35s 74ms/step - loss: 0.1584 - accuracy: 0.9531\n",
            "Epoch 26/30\n",
            "469/469 [==============================] - 37s 78ms/step - loss: 0.1552 - accuracy: 0.9539\n",
            "Epoch 27/30\n",
            "469/469 [==============================] - 36s 77ms/step - loss: 0.1507 - accuracy: 0.9548\n",
            "Epoch 28/30\n",
            "469/469 [==============================] - 36s 78ms/step - loss: 0.1474 - accuracy: 0.9569\n",
            "Epoch 29/30\n",
            "469/469 [==============================] - 37s 79ms/step - loss: 0.1442 - accuracy: 0.9566\n",
            "Epoch 30/30\n",
            "469/469 [==============================] - 36s 76ms/step - loss: 0.1410 - accuracy: 0.9574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the model using the mnist test sample"
      ],
      "metadata": {
        "id": "rwy_FxRTFgbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test2_loss,test2_acc=model2.evaluate(test_images,test_labels,verbose=2)\n",
        "print(\"The accuracy of the trained model is \", test2_acc *100, \"%\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t59HLvCtXrIu",
        "outputId": "260fa782-cff6-46e9-9115-8d5bdf70dbaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 3s - loss: 0.1221 - accuracy: 0.9607 - 3s/epoch - 9ms/step\n",
            "The accuracy of the trained model is  96.069997549057 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comment on the performance of both model\n",
        "By using multiple convolutional layer, we have achieve a better accuracy of 96% compare to a single convolutional layer with accuracy of 95%. This is because by using multiple convolutional layer we can further reduce the chance of overfitting the model to the training data."
      ],
      "metadata": {
        "id": "ry1mR0PJ-bX_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uyNlspSrW-dJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}